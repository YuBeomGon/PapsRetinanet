{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ca2bbc34-572b-453a-9253-207444de1e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1af2cf8c-32a3-4a6d-9f18-27d588d50bce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timm.list_models('vision*', pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "561b72c5-4c41-47be-b08c-0317e7f667e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['efficientnet_b0',\n",
       " 'efficientnet_b1',\n",
       " 'efficientnet_b1_pruned',\n",
       " 'efficientnet_b2',\n",
       " 'efficientnet_b2_pruned',\n",
       " 'efficientnet_b2a',\n",
       " 'efficientnet_b3',\n",
       " 'efficientnet_b3_pruned',\n",
       " 'efficientnet_b3a',\n",
       " 'efficientnet_b4',\n",
       " 'efficientnet_b5',\n",
       " 'efficientnet_b6',\n",
       " 'efficientnet_b7',\n",
       " 'efficientnet_b8',\n",
       " 'efficientnet_cc_b0_4e',\n",
       " 'efficientnet_cc_b0_8e',\n",
       " 'efficientnet_cc_b1_8e',\n",
       " 'efficientnet_el',\n",
       " 'efficientnet_el_pruned',\n",
       " 'efficientnet_em',\n",
       " 'efficientnet_es',\n",
       " 'efficientnet_es_pruned',\n",
       " 'efficientnet_l2',\n",
       " 'efficientnet_lite0',\n",
       " 'efficientnet_lite1',\n",
       " 'efficientnet_lite2',\n",
       " 'efficientnet_lite3',\n",
       " 'efficientnet_lite4',\n",
       " 'efficientnetv2_l',\n",
       " 'efficientnetv2_m',\n",
       " 'efficientnetv2_rw_m',\n",
       " 'efficientnetv2_rw_s',\n",
       " 'efficientnetv2_rw_t',\n",
       " 'efficientnetv2_s',\n",
       " 'efficientnetv2_xl']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timm.list_models('effi*', pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b1f15fce-5c3c-42f7-a7e9-a52b2d891d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = timm.create_model('efficientnet_b5', features_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7b8d4bf2-ed65-4d68-a257-8972d03e6b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(torch.randn(2,3,300,300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "792c34f0-9129-4392-8200-1351f49233ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 24, 150, 150])\n",
      "torch.Size([2, 40, 75, 75])\n",
      "torch.Size([2, 64, 38, 38])\n",
      "torch.Size([2, 176, 19, 19])\n",
      "torch.Size([2, 512, 10, 10])\n"
     ]
    }
   ],
   "source": [
    "for o in out :\n",
    "    print(o.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "06a72ea1-f717-472d-81ae-acd8efcebf3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[64, 176, 512]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.feature_info.channels()[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ab578907-a9de-4a4f-9d46-0ba5e7c9336f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[24, 40, 64, 176, 512]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.feature_info.channels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2340c7e7-428d-4a1d-8048-10744947d7d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[512, 176, 64, 40, 24]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.feature_info.channels()[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d4bb692a-387b-4075-8dfc-de7071ac836c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = timm.create_model('resnet18', num_classes=0, global_pool='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "eecc7a6a-2b16-48a6-87c1-06de4f2b9809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 512, 64, 64])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_output = model(torch.randn(2,3,2048,2048))\n",
    "feature_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "29ce5a6c-d359-4820-be3a-9d17a3ce5a46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=512, out_features=6, bias=True)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a20838f3-df7c-4279-a84b-afec21a99759",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 512, 64, 64])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = model.forward_features(torch.randn(2,3,2048,2048))\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c23874-8db3-406d-9f20-ef5a698b033d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9720bfa9-6fa3-4633-aaac-7c3e7fdd700c",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "features_only not implemented for Vision Transformer models.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_506/2385378363.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'swin_base_patch4_window7_224'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/timm/models/factory.py\u001b[0m in \u001b[0;36mcreate_model\u001b[0;34m(model_name, pretrained, checkpoint_path, scriptable, exportable, no_jit, **kwargs)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mset_layer_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscriptable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscriptable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexportable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexportable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_jit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mno_jit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/timm/models/swin_transformer.py\u001b[0m in \u001b[0;36mswin_base_patch4_window7_224\u001b[0;34m(pretrained, **kwargs)\u001b[0m\n\u001b[1;32m    583\u001b[0m     model_kwargs = dict(\n\u001b[1;32m    584\u001b[0m         patch_size=4, window_size=7, embed_dim=128, depths=(2, 2, 18, 2), num_heads=(4, 8, 16, 32), **kwargs)\n\u001b[0;32m--> 585\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_create_swin_transformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'swin_base_patch4_window7_224'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/timm/models/swin_transformer.py\u001b[0m in \u001b[0;36m_create_swin_transformer\u001b[0;34m(variant, pretrained, default_cfg, **kwargs)\u001b[0m\n\u001b[1;32m    554\u001b[0m     \u001b[0mimg_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'img_size'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_img_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'features_only'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'features_only not implemented for Vision Transformer models.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m     model = build_model_with_cfg(\n",
      "\u001b[0;31mRuntimeError\u001b[0m: features_only not implemented for Vision Transformer models."
     ]
    }
   ],
   "source": [
    "model = timm.create_model('swin_base_patch4_window7_224', features_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2469ba88-9c2b-407a-a979-fe6451bdb256",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
