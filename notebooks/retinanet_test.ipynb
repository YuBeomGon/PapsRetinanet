{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21475843-3fb8-4d70-96eb-84bc0afcc916",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "from collections import OrderedDict\n",
    "from typing import Dict, List, Optional, Callable\n",
    "import timm\n",
    "\n",
    "import torchvision\n",
    "from torchvision.models._utils import IntermediateLayerGetter\n",
    "from torchvision import models\n",
    "from torchvision.ops.feature_pyramid_network import FeaturePyramidNetwork, LastLevelMaxPool, ExtraFPNBlock, LastLevelP6P7\n",
    "from torchvision.ops.misc import FrozenBatchNorm2d\n",
    "\n",
    "from torchvision.models.detection.backbone_utils import BackboneWithFPN\n",
    "from torchvision.models.detection.retinanet import RetinaNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f799d7a-be56-48cb-839d-a029e2158678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# backbone = models.__dict__['resnet18']\n",
    "backbone = torchvision.models.resnet18(pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84848dfe-dbb3-4df7-83a9-96316128720f",
   "metadata": {},
   "outputs": [],
   "source": [
    "returned_layers = [2,3,4]\n",
    "return_layers = {f\"layer{k}\": str(v) for v, k in enumerate(returned_layers)}\n",
    "# #in_channels_stage2 = backbone.inplanes // 8\n",
    "# in_channels_list = [in_channels_stage2 * 2 ** (i - 1) for i in returned_layers]\n",
    "in_channels_list = [128, 256, 512]\n",
    "out_channels = 256\n",
    "extra_blocks = LastLevelP6P7(256,256)\n",
    "body = IntermediateLayerGetter(backbone, return_layers=return_layers)\n",
    "fpn = FeaturePyramidNetwork(\n",
    "    in_channels_list=in_channels_list,\n",
    "    out_channels=out_channels,\n",
    "    extra_blocks=extra_blocks,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c854e125-8afc-4bee-a112-ff49c981358f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['0', '1', '2'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "out = body(torch.randn(2,3,512,512))\n",
    "out.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "979a8b83-878e-4c05-b1e6-139fa0c818f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "collections.OrderedDict"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5b9b8c7-f42f-430f-8331-7c95a4918863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 128, 64, 64])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out['0'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "224f1ef3-af62-49c9-b206-b0bf925f4666",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 256, 32, 32])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out['1'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6ae956a-d026-4d77-9115-372cda35f0fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 512, 16, 16])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out['2'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f558fbf5-c85c-4533-b170-cd898a3a55a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpn_out = fpn(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e46a6e4b-959f-4312-816b-c77aad408550",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['0', '1', '2', 'p6', 'p7'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpn_out.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47b81169-01d6-49e0-9937-2a1ec1c22653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 256, 64, 64])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpn_out['0'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3087b63a-49b5-4e3e-a6b8-53e7c4d17e83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 256, 32, 32])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpn_out['1'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3e0f31c-d69e-4f88-b0c0-e2ab57c47adc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 256, 16, 16])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpn_out['2'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06c4c927-b0b7-4e25-9c04-d936c3a2ee47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 256, 8, 8])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpn_out['p6'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bb025a37-1b4d-40bd-a718-6618f2d5b944",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 256, 4, 4])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpn_out['p7'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812745ac-8a3d-4e1c-8938-ea9bb18cb875",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d1d78437-70a6-4ba0-8156-943bb1d6c879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# backbone = torchvision.models.resnet18(pretrained=False)\n",
    "# backbone = timm.create_model('resnet18', features_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f5799eb2-a8cb-4a27-ab6d-6260494630c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "returned_layers = [2,3,4]\n",
    "return_layers = {f\"layer{k}\": str(v) for v, k in enumerate(returned_layers)}\n",
    "# #in_channels_stage2 = backbone.inplanes // 8\n",
    "# in_channels_list = [in_channels_stage2 * 2 ** (i - 1) for i in returned_layers]\n",
    "in_channels_list = [128, 256, 512]\n",
    "out_channels = 256\n",
    "extra_blocks = LastLevelP6P7(256,256)\n",
    "body = timm.create_model('resnet18', features_only=True)\n",
    "fpn = FeaturePyramidNetwork(\n",
    "    in_channels_list=in_channels_list,\n",
    "    out_channels=out_channels,\n",
    "    extra_blocks=extra_blocks,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e1212d13-11f3-4b91-be32-448f3353bb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "o = body(torch.randn(2,3,512,512))\n",
    "out = OrderedDict()\n",
    "out['0'] = o[-3]\n",
    "out['1'] = o[-2]\n",
    "out['2'] = o[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5f97dcb1-2da0-43ee-803e-c21d37e4db93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['0', '1', '2'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "01812fac-44ab-415e-93e8-635da451201c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpn_out = fpn(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a2a99cc6-08ef-4c16-9b76-cb4058b3a960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['0', '1', '2', 'p6', 'p7'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpn_out.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "79fa74f3-e373-4a3b-9e13-f7a2228d8fcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 256, 64, 64])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpn_out['0'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "62d1376c-5b63-4cd4-9528-ce52bc6504e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 256, 16, 16])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpn_out['2'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dc6ed90f-f7ca-44bf-a29d-97c7a4e126ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 256, 8, 8])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpn_out['p6'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf9a47b-2d57-4984-8fb2-7c63085011e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c771ff96-4415-4872-b310-a08ab5c49151",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet_fpn_backbone(\n",
    "    backbone_name: str,\n",
    "    pretrained: bool,\n",
    "    norm_layer: Callable[..., nn.Module] =  FrozenBatchNorm2d, \n",
    "    trainable_layers: int = 3,\n",
    "    returned_layers: Optional[List[int]] = None,\n",
    "    extra_blocks: Optional[ExtraFPNBlock] = None,\n",
    ") -> BackboneWithFPN:\n",
    "\n",
    "    # select layers that wont be frozen\n",
    "    backbone = torchvision.models.__dict__[backbone_name](pretrained=pretrained, norm_layer=norm_layer)\n",
    "    assert 0 <= trainable_layers <= 5\n",
    "    layers_to_train = [\"layer4\", \"layer3\", \"layer2\", \"layer1\", \"conv1\"][:trainable_layers]\n",
    "    if trainable_layers == 5:\n",
    "        layers_to_train.append(\"bn1\")\n",
    "    for name, parameter in backbone.named_parameters():\n",
    "        if all([not name.startswith(layer) for layer in layers_to_train]):\n",
    "            parameter.requires_grad_(False)\n",
    "\n",
    "    if extra_blocks is None:\n",
    "        extra_blocks = LastLevelMaxPool()\n",
    "\n",
    "    if returned_layers is None:\n",
    "        returned_layers = [1, 2, 3, 4]\n",
    "    assert min(returned_layers) > 0 and max(returned_layers) < 5\n",
    "    return_layers = {f\"layer{k}\": str(v) for v, k in enumerate(returned_layers)}\n",
    "\n",
    "    in_channels_stage2 = backbone.inplanes // 8\n",
    "    in_channels_list = [in_channels_stage2 * 2 ** (i - 1) for i in returned_layers]\n",
    "    out_channels = 256\n",
    "    return BackboneWithFPN(backbone, return_layers, in_channels_list, out_channels, extra_blocks=extra_blocks)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6debdb4a-ac52-4c24-8549-4c7ce7d28f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = resnet_fpn_backbone('resnet18', pretrained=True, trainable_layers=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9af73b11-7e5f-4015-8bb5-2a17c2de6ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RetinaNet(backbone,\n",
    "                  num_classes=1,\n",
    "                  anchor_generator=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6b9a29a6-57e6-4f80-bb92-1b2ce00188f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/beomgon/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1639180543123/work/aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'boxes': tensor([], size=(0, 4), grad_fn=<StackBackward0>),\n",
       "  'scores': tensor([], grad_fn=<IndexBackward0>),\n",
       "  'labels': tensor([], dtype=torch.int64)},\n",
       " {'boxes': tensor([], size=(0, 4), grad_fn=<StackBackward0>),\n",
       "  'scores': tensor([], grad_fn=<IndexBackward0>),\n",
       "  'labels': tensor([], dtype=torch.int64)}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "model(torch.randn(2,3,500,500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1c4ca9-6d9b-4bd5-a094-42a1c8d09326",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a5e784dd-cc0e-4124-8ee5-6400cd0db372",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BackboneWithFPN(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        backbone: str,\n",
    "        in_channels_list: List[int] = [128,256,512],\n",
    "        out_channels: int = 256,\n",
    "        extra_blocks: Optional[ExtraFPNBlock] = None,\n",
    "    ) -> None:\n",
    "        super(BackboneWithFPN, self).__init__()\n",
    "\n",
    "        if extra_blocks is None:\n",
    "            extra_blocks = LastLevelMaxPool()\n",
    "        self.in_channels_list = in_channels_list\n",
    "        self.out_channels = out_channels\n",
    "        self.extra_block = LastLevelP6P7(out_channels,out_channels)\n",
    "\n",
    "        self.body = timm.create_model(backbone, features_only=True)\n",
    "        self.fpn = FeaturePyramidNetwork(\n",
    "            in_channels_list=self.in_channels_list,\n",
    "            out_channels=self.out_channels,\n",
    "            extra_blocks=self.extra_block,\n",
    "        )\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "    def forward(self, x: Tensor) -> Dict[str, Tensor]:\n",
    "        out = OrderedDict()\n",
    "        x = self.body(x)\n",
    "        out['0'] = x[-3]\n",
    "        out['1'] = x[-2]\n",
    "        out['2'] = x[-1]        \n",
    "        out = self.fpn(out)\n",
    "        print(out.keys())\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d3e59cd4-0131-4b16-aa94-b396ce8adf99",
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = BackboneWithFPN('resnet18')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bce0cb8d-fa8c-4aa8-9460-90fe23986fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['0', '1', '2', 'p6', 'p7'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'boxes': tensor([], size=(0, 4), grad_fn=<StackBackward0>),\n",
       "  'scores': tensor([], grad_fn=<IndexBackward0>),\n",
       "  'labels': tensor([], dtype=torch.int64)},\n",
       " {'boxes': tensor([], size=(0, 4), grad_fn=<StackBackward0>),\n",
       "  'scores': tensor([], grad_fn=<IndexBackward0>),\n",
       "  'labels': tensor([], dtype=torch.int64)}]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RetinaNet(backbone,\n",
    "                  num_classes=1,\n",
    "                  anchor_generator=None)\n",
    "\n",
    "model.eval()\n",
    "model(torch.randn(2,3,500,500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b6a3a1-63d6-4c35-ac9c-31b24194edf7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
