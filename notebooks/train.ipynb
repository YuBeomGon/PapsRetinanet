{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6680c406-78bd-4ef6-816d-3885202713a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/beomgon/anaconda3/envs/pl/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import timm\n",
    "import logging\n",
    "import argparse\n",
    "import pandas as pd\n",
    "from typing import Optional\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset\n",
    "from torchmetrics import Accuracy, F1Score, Specificity\n",
    "\n",
    "from pytorch_lightning import LightningModule\n",
    "from pytorch_lightning.lite import LightningLite\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, TQDMProgressBar\n",
    "from pytorch_lightning.strategies import ParallelStrategy\n",
    "from pytorch_lightning.utilities.cli import LightningCLI\n",
    "from pytorch_lightning import Trainer\n",
    "# from pytorch_lightning import loggers as pl_loggers\n",
    "from pytorch_lightning.loggers import TensorBoardLogger, WandbLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping, LearningRateMonitor\n",
    "from pytorch_lightning.plugins import DDPPlugin\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from utils.dataset import PapsClsDataset, train_transforms, val_transforms, test_transforms, MAX_IMAGE_SIZE\n",
    "from utils.collate import collate_fn\n",
    "# from utils.sampler_by_group import GroupedBatchSampler, create_area_groups\n",
    "from utils.losses import SupConLoss, FocalLoss\n",
    "\n",
    "# from cls_utils.block import Bottleneck, TwoMLPHead, RoIPool\n",
    "from cls_utils.model import PapsClassificationModel\n",
    "from utils.collate import collate_fn\n",
    "from utils.sampler import get_weight_random_sampler\n",
    "from train_cls import PapsClsModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99e1cf60-efff-4345-8d43-cadbc49ad2a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--output_dir'], dest='output_dir', nargs=None, const=None, default='./saved_models/classification', type=<class 'str'>, choices=None, help='directory for model checkpoint', metavar=None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description='PyTorch Lightning ImageNet Training')\n",
    "parser.add_argument('--data_path', metavar='DIR', default='./lbp_data/',\n",
    "                    help='path to dataset (default: ./lbp_data/)')\n",
    "parser.add_argument('-a', '--arch', metavar='ARCH', default='resnet18',\n",
    "                    help='model architecture: (default: resnet18)')\n",
    "parser.add_argument('-j', '--workers', default=12, type=int, metavar='N',\n",
    "                    help='number of data loading workers (default: 4)')\n",
    "parser.add_argument('--epochs', default=15, type=int, metavar='N',\n",
    "                    help='number of total epochs to run')\n",
    "parser.add_argument('-b', '--batch-size', default=16, type=int,\n",
    "                    metavar='N',\n",
    "                    help='mini-batch size (default: 256), this is the total '\n",
    "                         'batch size of all GPUs on the current node when '\n",
    "                         'using Data Parallel or Distributed Data Parallel')\n",
    "\n",
    "parser.add_argument('--lr', '--learning-rate', default=0.0005, type=float,\n",
    "                    metavar='LR', help='initial learning rate', dest='lr')\n",
    "\n",
    "parser.add_argument('--momentum', default=0.9, type=float, metavar='M',\n",
    "                    help='momentum')\n",
    "\n",
    "parser.add_argument('--wd', '--weight-decay', default=1e-4, type=float,\n",
    "                    metavar='W', help='weight decay (default: 1e-4)',\n",
    "                    dest='weight_decay')\n",
    "\n",
    "parser.add_argument('--accelerator', '--accelerator', default='gpu', type=str, help='default: gpu')\n",
    "\n",
    "parser.add_argument('--devices', '--devices', default=2, type=int, help='number of gpus, default 2')\n",
    "parser.add_argument('--img_size', default=400, type=int, help='input image resolution in swin models')\n",
    "parser.add_argument('--num_classes', default=6, type=int, help='number of classes')\n",
    "\n",
    "parser.add_argument('--pretrained', default=True, type=bool, help='set True if using pretrained weights')\n",
    "parser.add_argument('--output_dir', default='./saved_models/classification', type=str, help='directory for model checkpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f946d4fc-cf7f-4005-99c7-46325e67df1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "args = parser.parse_args([])\n",
    "if torch.cuda.is_available() :\n",
    "    args.accelerator = 'gpu'\n",
    "    args.devices = torch.cuda.device_count()\n",
    "\n",
    "args.img_size = MAX_IMAGE_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f23fa57-35f2-4f2d-aa07-2b8d812d6740",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.epochs = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d48870d-ef57-4985-9cac-b31a9ed5a231",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.data_path = '../lbp_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea2ffafb-90ff-4686-acf7-5173b348b40b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbeomgon-yu\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.17 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.16"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/beomgon/pytorch/scl/PapsRetinanet/notebooks/wandb/run-20220530_084851-12l2za7z</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/beomgon-yu/Paps_clf/runs/12l2za7z\" target=\"_blank\">20220530_084850</a></strong> to <a href=\"https://wandb.ai/beomgon-yu/Paps_clf\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> creating model 'resnet18'\n"
     ]
    }
   ],
   "source": [
    "logger_tb = TensorBoardLogger('./tuning_logs' +'/' + args.arch, name=now)\n",
    "logger_wandb = WandbLogger(project='Paps_clf', name=now, mode='online') # online or disabled    \n",
    "\n",
    "trainer_defaults = dict(\n",
    "    callbacks = [\n",
    "        # the PyTorch example refreshes every 10 batches\n",
    "        TQDMProgressBar(refresh_rate=50),\n",
    "        # save when the validation top1 accuracy improves\n",
    "        ModelCheckpoint(monitor=\"val_acc1\", mode=\"max\",\n",
    "                        dirpath=args.output_dir + '/' + args.arch,\n",
    "                        filename='paps_tunning_{epoch}_{val_acc1:.2f}'),  \n",
    "        ModelCheckpoint(monitor=\"val_acc1\", mode=\"max\",\n",
    "                        dirpath=args.output_dir + '/' + args.arch,\n",
    "                        filename='paps_tunning_best'),             \n",
    "    ],    \n",
    "    # plugins = \"deepspeed_stage_2_offload\",\n",
    "    precision = 16,\n",
    "    max_epochs = args.epochs,\n",
    "    accelerator = args.accelerator, # auto, or select device, \"gpu\"\n",
    "    # devices = args.devices, # number of gpus\n",
    "    # devices = 1, # number of gpus\n",
    "    logger = [logger_tb, logger_wandb],\n",
    "    benchmark = True,\n",
    "    # strategy = \"ddp\",\n",
    "    replace_sampler_ddp=False,\n",
    "    gpus=[1],\n",
    "    )\n",
    "\n",
    "model = PapsClsModel(\n",
    "    data_path=args.data_path,\n",
    "    arch=args.arch,\n",
    "    pretrained=args.pretrained,\n",
    "    workers=args.workers,\n",
    "    lr = args.lr,\n",
    "    batch_size=args.batch_size,\n",
    "    weight_decay=args.weight_decay,\n",
    "    num_classes=args.num_classes,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d639c3-4c08-4ff4-b9cb-224d22d22c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17828, 16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/beomgon/anaconda3/envs/pl/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:611: UserWarning: Checkpoint directory /home/beomgon/pytorch/scl/PapsRetinanet/notebooks/saved_models/classification/resnet18 exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5449, 16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name        | Type                    | Params\n",
      "--------------------------------------------------------\n",
      "0 | model       | PapsClassificationModel | 11.7 M\n",
      "1 | criterion   | CrossEntropyLoss        | 0     \n",
      "2 | train_acc1  | Accuracy                | 0     \n",
      "3 | eval_acc1   | Accuracy                | 0     \n",
      "4 | f1          | F1Score                 | 0     \n",
      "5 | specificity | Specificity             | 0     \n",
      "--------------------------------------------------------\n",
      "11.7 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.7 M    Total params\n",
      "23.474    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/1456 [00:00<?, ?it/s]                          "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/beomgon/anaconda3/envs/pl/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  76%|███████▌  | 1100/1456 [13:27<04:21,  1.36it/s, loss=0.931, v_num=za7z, train_acc=0.562]\n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0:  79%|███████▉  | 1150/1456 [14:12<03:46,  1.35it/s, loss=0.931, v_num=za7z, train_acc=0.562]\n",
      "Epoch 0:  82%|████████▏ | 1200/1456 [14:45<03:08,  1.36it/s, loss=0.931, v_num=za7z, train_acc=0.562]\n",
      "Epoch 0:  86%|████████▌ | 1250/1456 [15:17<02:31,  1.36it/s, loss=0.931, v_num=za7z, train_acc=0.562]\n",
      "Epoch 0:  89%|████████▉ | 1300/1456 [15:49<01:53,  1.37it/s, loss=0.931, v_num=za7z, train_acc=0.562]\n",
      "Epoch 0:  93%|█████████▎| 1350/1456 [16:22<01:17,  1.37it/s, loss=0.931, v_num=za7z, train_acc=0.562]\n",
      "Epoch 0:  96%|█████████▌| 1400/1456 [16:51<00:40,  1.38it/s, loss=0.931, v_num=za7z, train_acc=0.562]\n",
      "Epoch 0: 100%|█████████▉| 1450/1456 [17:21<00:04,  1.39it/s, loss=0.931, v_num=za7z, train_acc=0.562]\n",
      "Epoch 0: 100%|██████████| 1456/1456 [17:24<00:00,  1.39it/s, loss=0.93, v_num=za7z, train_acc=0.750, val_acc1=0.535, val_f1_score=0.486, val_specificity=0.886]\n",
      "Epoch 1:  76%|███████▌  | 1100/1456 [30:53<09:59,  1.68s/it, loss=0.893, v_num=za7z, train_acc=0.625, val_acc1=0.535, val_f1_score=0.486, val_specificity=0.886] \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 1:  79%|███████▉  | 1150/1456 [31:33<08:23,  1.65s/it, loss=0.893, v_num=za7z, train_acc=0.625, val_acc1=0.535, val_f1_score=0.486, val_specificity=0.886]\n",
      "Epoch 1:  82%|████████▏ | 1200/1456 [32:09<06:51,  1.61s/it, loss=0.893, v_num=za7z, train_acc=0.625, val_acc1=0.535, val_f1_score=0.486, val_specificity=0.886]\n",
      "Epoch 1:  86%|████████▌ | 1250/1456 [32:41<05:23,  1.57s/it, loss=0.893, v_num=za7z, train_acc=0.625, val_acc1=0.535, val_f1_score=0.486, val_specificity=0.886]\n",
      "Epoch 1:  89%|████████▉ | 1300/1456 [33:15<03:59,  1.54s/it, loss=0.893, v_num=za7z, train_acc=0.625, val_acc1=0.535, val_f1_score=0.486, val_specificity=0.886]\n",
      "Epoch 1:  93%|█████████▎| 1350/1456 [33:46<02:39,  1.50s/it, loss=0.893, v_num=za7z, train_acc=0.625, val_acc1=0.535, val_f1_score=0.486, val_specificity=0.886]\n",
      "Epoch 1:  96%|█████████▌| 1400/1456 [34:20<01:22,  1.47s/it, loss=0.893, v_num=za7z, train_acc=0.625, val_acc1=0.535, val_f1_score=0.486, val_specificity=0.886]\n",
      "Epoch 1: 100%|█████████▉| 1450/1456 [34:50<00:08,  1.44s/it, loss=0.893, v_num=za7z, train_acc=0.625, val_acc1=0.535, val_f1_score=0.486, val_specificity=0.886]\n",
      "Epoch 1: 100%|██████████| 1456/1456 [34:53<00:00,  1.44s/it, loss=0.847, v_num=za7z, train_acc=0.750, val_acc1=0.531, val_f1_score=0.435, val_specificity=0.896]\n",
      "Epoch 2:  76%|███████▌  | 1100/1456 [48:49<15:47,  2.66s/it, loss=0.758, v_num=za7z, train_acc=0.562, val_acc1=0.531, val_f1_score=0.435, val_specificity=0.896] \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 2:  79%|███████▉  | 1150/1456 [49:27<13:09,  2.58s/it, loss=0.758, v_num=za7z, train_acc=0.562, val_acc1=0.531, val_f1_score=0.435, val_specificity=0.896]\n",
      "Epoch 2:  82%|████████▏ | 1200/1456 [50:00<10:40,  2.50s/it, loss=0.758, v_num=za7z, train_acc=0.562, val_acc1=0.531, val_f1_score=0.435, val_specificity=0.896]\n",
      "Epoch 2:  86%|████████▌ | 1250/1456 [50:33<08:19,  2.43s/it, loss=0.758, v_num=za7z, train_acc=0.562, val_acc1=0.531, val_f1_score=0.435, val_specificity=0.896]\n",
      "Epoch 2:  89%|████████▉ | 1300/1456 [51:05<06:07,  2.36s/it, loss=0.758, v_num=za7z, train_acc=0.562, val_acc1=0.531, val_f1_score=0.435, val_specificity=0.896]\n",
      "Epoch 2:  93%|█████████▎| 1350/1456 [51:38<04:03,  2.30s/it, loss=0.758, v_num=za7z, train_acc=0.562, val_acc1=0.531, val_f1_score=0.435, val_specificity=0.896]\n",
      "Epoch 2:  96%|█████████▌| 1400/1456 [52:11<02:05,  2.24s/it, loss=0.758, v_num=za7z, train_acc=0.562, val_acc1=0.531, val_f1_score=0.435, val_specificity=0.896]\n",
      "Epoch 2: 100%|█████████▉| 1450/1456 [52:40<00:13,  2.18s/it, loss=0.758, v_num=za7z, train_acc=0.562, val_acc1=0.531, val_f1_score=0.435, val_specificity=0.896]\n",
      "Epoch 2: 100%|██████████| 1456/1456 [52:42<00:00,  2.17s/it, loss=0.785, v_num=za7z, train_acc=0.750, val_acc1=0.571, val_f1_score=0.459, val_specificity=0.887]\n",
      "Epoch 3:  76%|███████▌  | 1100/1456 [1:06:17<21:27,  3.62s/it, loss=0.661, v_num=za7z, train_acc=0.625, val_acc1=0.571, val_f1_score=0.459, val_specificity=0.887] \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 3:  79%|███████▉  | 1150/1456 [1:07:00<17:49,  3.50s/it, loss=0.661, v_num=za7z, train_acc=0.625, val_acc1=0.571, val_f1_score=0.459, val_specificity=0.887]\n",
      "Epoch 3:  82%|████████▏ | 1200/1456 [1:07:31<14:24,  3.38s/it, loss=0.661, v_num=za7z, train_acc=0.625, val_acc1=0.571, val_f1_score=0.459, val_specificity=0.887]\n",
      "Epoch 3:  86%|████████▌ | 1250/1456 [1:08:05<11:13,  3.27s/it, loss=0.661, v_num=za7z, train_acc=0.625, val_acc1=0.571, val_f1_score=0.459, val_specificity=0.887]\n",
      "Epoch 3:  89%|████████▉ | 1300/1456 [1:08:36<08:13,  3.17s/it, loss=0.661, v_num=za7z, train_acc=0.625, val_acc1=0.571, val_f1_score=0.459, val_specificity=0.887]\n",
      "Epoch 3:  93%|█████████▎| 1350/1456 [1:09:05<05:25,  3.07s/it, loss=0.661, v_num=za7z, train_acc=0.625, val_acc1=0.571, val_f1_score=0.459, val_specificity=0.887]\n",
      "Epoch 3:  96%|█████████▌| 1400/1456 [1:09:37<02:47,  2.98s/it, loss=0.661, v_num=za7z, train_acc=0.625, val_acc1=0.571, val_f1_score=0.459, val_specificity=0.887]\n",
      "Epoch 3: 100%|█████████▉| 1450/1456 [1:10:06<00:17,  2.90s/it, loss=0.661, v_num=za7z, train_acc=0.625, val_acc1=0.571, val_f1_score=0.459, val_specificity=0.887]\n",
      "Epoch 3: 100%|██████████| 1456/1456 [1:10:09<00:00,  2.89s/it, loss=0.627, v_num=za7z, train_acc=0.250, val_acc1=0.625, val_f1_score=0.557, val_specificity=0.911]\n",
      "Epoch 4:  76%|███████▌  | 1100/1456 [1:23:48<27:07,  4.57s/it, loss=0.541, v_num=za7z, train_acc=0.688, val_acc1=0.625, val_f1_score=0.557, val_specificity=0.911]  \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 4:  79%|███████▉  | 1150/1456 [1:24:29<22:28,  4.41s/it, loss=0.541, v_num=za7z, train_acc=0.688, val_acc1=0.625, val_f1_score=0.557, val_specificity=0.911]\n",
      "Epoch 4:  82%|████████▏ | 1200/1456 [1:25:03<18:08,  4.25s/it, loss=0.541, v_num=za7z, train_acc=0.688, val_acc1=0.625, val_f1_score=0.557, val_specificity=0.911]\n",
      "Epoch 4:  86%|████████▌ | 1250/1456 [1:25:34<14:06,  4.11s/it, loss=0.541, v_num=za7z, train_acc=0.688, val_acc1=0.625, val_f1_score=0.557, val_specificity=0.911]\n",
      "Epoch 4:  89%|████████▉ | 1300/1456 [1:26:08<10:20,  3.98s/it, loss=0.541, v_num=za7z, train_acc=0.688, val_acc1=0.625, val_f1_score=0.557, val_specificity=0.911]\n",
      "Epoch 4:  93%|█████████▎| 1350/1456 [1:26:40<06:48,  3.85s/it, loss=0.541, v_num=za7z, train_acc=0.688, val_acc1=0.625, val_f1_score=0.557, val_specificity=0.911]\n",
      "Epoch 4:  96%|█████████▌| 1400/1456 [1:27:13<03:29,  3.74s/it, loss=0.541, v_num=za7z, train_acc=0.688, val_acc1=0.625, val_f1_score=0.557, val_specificity=0.911]\n",
      "Epoch 4: 100%|█████████▉| 1450/1456 [1:27:44<00:21,  3.63s/it, loss=0.541, v_num=za7z, train_acc=0.688, val_acc1=0.625, val_f1_score=0.557, val_specificity=0.911]\n",
      "Epoch 4: 100%|██████████| 1456/1456 [1:27:46<00:00,  3.62s/it, loss=0.584, v_num=za7z, train_acc=1.000, val_acc1=0.585, val_f1_score=0.510, val_specificity=0.904]\n",
      "Epoch 5:  76%|███████▌  | 1100/1456 [1:41:39<32:54,  5.55s/it, loss=0.594, v_num=za7z, train_acc=0.750, val_acc1=0.585, val_f1_score=0.510, val_specificity=0.904]  \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 5:  79%|███████▉  | 1150/1456 [1:42:19<27:13,  5.34s/it, loss=0.594, v_num=za7z, train_acc=0.750, val_acc1=0.585, val_f1_score=0.510, val_specificity=0.904]\n",
      "Epoch 5:  82%|████████▏ | 1200/1456 [1:42:53<21:56,  5.14s/it, loss=0.594, v_num=za7z, train_acc=0.750, val_acc1=0.585, val_f1_score=0.510, val_specificity=0.904]\n",
      "Epoch 5:  86%|████████▌ | 1250/1456 [1:43:25<17:02,  4.96s/it, loss=0.594, v_num=za7z, train_acc=0.750, val_acc1=0.585, val_f1_score=0.510, val_specificity=0.904]\n",
      "Epoch 5:  89%|████████▉ | 1300/1456 [1:43:57<12:28,  4.80s/it, loss=0.594, v_num=za7z, train_acc=0.750, val_acc1=0.585, val_f1_score=0.510, val_specificity=0.904]\n",
      "Epoch 5:  93%|█████████▎| 1350/1456 [1:44:28<08:12,  4.64s/it, loss=0.594, v_num=za7z, train_acc=0.750, val_acc1=0.585, val_f1_score=0.510, val_specificity=0.904]\n",
      "Epoch 5:  96%|█████████▌| 1400/1456 [1:45:01<04:12,  4.50s/it, loss=0.594, v_num=za7z, train_acc=0.750, val_acc1=0.585, val_f1_score=0.510, val_specificity=0.904]\n",
      "Epoch 5: 100%|█████████▉| 1450/1456 [1:45:30<00:26,  4.37s/it, loss=0.594, v_num=za7z, train_acc=0.750, val_acc1=0.585, val_f1_score=0.510, val_specificity=0.904]\n",
      "Epoch 5: 100%|██████████| 1456/1456 [1:45:32<00:00,  4.35s/it, loss=0.582, v_num=za7z, train_acc=1.000, val_acc1=0.663, val_f1_score=0.615, val_specificity=0.918]\n",
      "Epoch 6:  76%|███████▌  | 1100/1456 [1:59:10<38:34,  6.50s/it, loss=0.574, v_num=za7z, train_acc=0.562, val_acc1=0.663, val_f1_score=0.615, val_specificity=0.918]  \n",
      "Validation: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 6:  79%|███████▉  | 1150/1456 [1:59:50<31:53,  6.25s/it, loss=0.574, v_num=za7z, train_acc=0.562, val_acc1=0.663, val_f1_score=0.615, val_specificity=0.918]\n",
      "Epoch 6:  82%|████████▏ | 1200/1456 [2:00:23<25:40,  6.02s/it, loss=0.574, v_num=za7z, train_acc=0.562, val_acc1=0.663, val_f1_score=0.615, val_specificity=0.918]\n",
      "Epoch 6:  86%|████████▌ | 1250/1456 [2:00:56<19:55,  5.81s/it, loss=0.574, v_num=za7z, train_acc=0.562, val_acc1=0.663, val_f1_score=0.615, val_specificity=0.918]\n",
      "Epoch 6:  89%|████████▉ | 1300/1456 [2:01:29<14:34,  5.61s/it, loss=0.574, v_num=za7z, train_acc=0.562, val_acc1=0.663, val_f1_score=0.615, val_specificity=0.918]\n",
      "Epoch 6:  93%|█████████▎| 1350/1456 [2:02:04<09:35,  5.43s/it, loss=0.574, v_num=za7z, train_acc=0.562, val_acc1=0.663, val_f1_score=0.615, val_specificity=0.918]\n",
      "Epoch 6:  96%|█████████▌| 1400/1456 [2:02:35<04:54,  5.25s/it, loss=0.574, v_num=za7z, train_acc=0.562, val_acc1=0.663, val_f1_score=0.615, val_specificity=0.918]\n",
      "Epoch 6: 100%|█████████▉| 1450/1456 [2:03:05<00:30,  5.09s/it, loss=0.574, v_num=za7z, train_acc=0.562, val_acc1=0.663, val_f1_score=0.615, val_specificity=0.918]\n",
      "Epoch 6: 100%|██████████| 1456/1456 [2:03:07<00:00,  5.07s/it, loss=0.602, v_num=za7z, train_acc=0.500, val_acc1=0.635, val_f1_score=0.548, val_specificity=0.901]\n",
      "Epoch 7:  38%|███▊      | 550/1456 [2:10:05<3:34:18, 14.19s/it, loss=0.533, v_num=za7z, train_acc=0.812, val_acc1=0.635, val_f1_score=0.548, val_specificity=0.901] "
     ]
    }
   ],
   "source": [
    "trainer = Trainer(**trainer_defaults)\n",
    "trainer.fit(model)  \n",
    "\n",
    "trainer.test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5332676-dfb6-459e-a2f1-e7324e593774",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae552c5-d494-48b7-95a6-fa87d9af4abf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pl",
   "language": "python",
   "name": "pl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
